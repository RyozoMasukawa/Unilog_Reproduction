{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "848dabf6-49fa-411b-9477-4bce9ca90d01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "import wordninja\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, default_data_collator, get_scheduler\n",
    "from hf_transformers.src.transformers.models.bert.configuration_bert import BertConfig\n",
    "from hf_transformers.src.transformers.models.bert.modeling_bert import BertForPreTraining\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import collections\n",
    "\n",
    "\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3accd1b-045a-420c-8771-36d6821747e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.31.0.dev0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f44bce-4cfc-497d-927d-ce3ed5949837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#NOTE\n",
    "#ここで記号を区切ってwordninjaで塊除去を行っている\n",
    "#なお, かなり時間がかかるので実行には注意が必要\n",
    "#もう少し賢く書きたかったが, その書き方を思いつく時間とナイーブに実行する時間はどうせ同じぐらいだろう\n",
    "def preprocess_log(text):\n",
    "    text = text.replace('[', \" \")\n",
    "    text = text.replace(\".\", \" \")\n",
    "    text = text.replace(\",\", \" \")\n",
    "    text = text.replace(\":\", \" \")\n",
    "    text = text.replace(\"/\", \" \")\n",
    "    text = text.replace(\";\", \" \")\n",
    "    text = text.replace(\"=\", \" \")\n",
    "    text = text.replace(\"*\", \" \")\n",
    "    text = text.replace(\"_\", \" \")\n",
    "    text = text.replace(\"-\", \" \")\n",
    "    text = text.lower()\n",
    "    text = \" \".join(wordninja.split(text))\n",
    "    remove_num = lambda eg : \" \".join([word for word in eg.split(\" \") if not word.isdigit()])\n",
    "    return remove_num(text)\n",
    "\n",
    "def preprocess_log_batch(example):\n",
    "    return {\n",
    "        \"input\": [preprocess_log(l) for l in example[\"input\"]],\n",
    "        \"summary\": [preprocess_log(l) for l in example[\"summary\"]]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59cfa0e9-3f7d-45a2-97b4-438241754845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log2list(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = [line.rstrip(\"\\n\") for line in f]\n",
    "    return lines\n",
    "\n",
    "#ログデータのロード\n",
    "hdfs = log2list(\"./LogSummary/data/summary/logs/hdfs.txt\")\n",
    "bgl = log2list(\"./LogSummary/data/summary/logs/bgl.txt\")\n",
    "hpc = log2list(\"./LogSummary/data/summary/logs/HPC.txt\")\n",
    "zookeeper = log2list(\"./LogSummary/data/summary/logs/Zookeeper.txt\")\n",
    "proxifier = log2list(\"./LogSummary/data/summary/logs/Proxifier.txt\")\n",
    "spark = log2list(\"./LogSummary/data/summary/logs/spark.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29156d5-d914-47b4-88a8-4dbe2c3dd336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_data ={\n",
    "    \"hdfs\":hdfs,\n",
    "    \"bgl\":bgl,\n",
    "    \"hpc\":hpc,\n",
    "    \"zookeeper\":zookeeper, \n",
    "    \"proxifier\":proxifier,\n",
    "    \"spark\":spark\n",
    "}\n",
    "\n",
    "regexp = re.compile(r\"#([0-9]+)#\")\n",
    "\n",
    "text_summary_pairs = {}\n",
    "summary_dict = {}\n",
    "curr_key = \"default\"\n",
    "summary_comes_next = False\n",
    "\n",
    "for data_name in summary_data.keys():\n",
    "    text_summary_pairs[data_name] = {}\n",
    "    for l in summary_data[data_name]:\n",
    "        if not l:\n",
    "            pass\n",
    "        elif regexp.search(l):\n",
    "            text_summary_pairs[data_name][l] = []\n",
    "            curr_key=l\n",
    "        elif \"#summary:#\" in l:\n",
    "            summary_comes_next = True\n",
    "        elif summary_comes_next:\n",
    "            for elem in text_summary_pairs[data_name][curr_key]:\n",
    "                elem.append(l)\n",
    "            summary_comes_next = False\n",
    "        else:\n",
    "            text_summary_pairs[data_name][curr_key].append([l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc61c1d6-509a-4a6b-a45b-61a478576675",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_output_pairs = []\n",
    "for key in text_summary_pairs.keys():\n",
    "    for k in text_summary_pairs[key]:\n",
    "        pair = text_summary_pairs[key][k]\n",
    "        input_output_pairs += pair\n",
    "\n",
    "invalid_indice = [i for i, pair in enumerate(input_output_pairs) if len(pair)!=2]\n",
    "for i in invalid_indice:\n",
    "    input_output_pairs.pop(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f888735d-da79-4bfc-ac55-9b6c8bfd9559",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11980, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4de78902-9a36-4577-9348-42a7a238d3d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"input\": np.array([p[0] for p in input_output_pairs]), \n",
    "        \"summary\": np.array([p[1] for p in input_output_pairs])\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0613897b-b42f-47a7-a909-85aff518ccc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_summary.to_csv(\"./logdata/log_summary_pairs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "856862c1-1d56-4f6d-b870-ee5553ae8cce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-00dcddb0e73b1160/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 8473.34it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1143.80it/s]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-00dcddb0e73b1160/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 649.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'summary'],\n",
       "        num_rows: 9584\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'summary'],\n",
       "        num_rows: 2396\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_summary = load_dataset(\"csv\", data_files=\"./logdata/log_summary_pairs.csv\")\n",
    "dataset_summary = dataset_summary[\"train\"].train_test_split(0.2)\n",
    "dataset_summary = dataset_summary.remove_columns(['Unnamed: 0'])\n",
    "dataset_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf549ef3-4376-4c63-b884-5e0220d567d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'summary'],\n",
       "        num_rows: 1198\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'summary'],\n",
       "        num_rows: 1198\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataset_summary[\"train\"]\n",
    "test_valid = dataset_summary[\"test\"].train_test_split(0.5)\n",
    "test_dataset = test_valid[\"test\"]\n",
    "eval_dataset = test_valid[\"train\"]\n",
    "test_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9732b8c1-9752-440e-a0f5-3add2c0389a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "train_data = train_data.map(\n",
    "    preprocess_log_batch,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f09fe6e7-8c2a-414a-a639-32f52ae288ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "eval_dataset = eval_dataset.map(\n",
    "    preprocess_log_batch,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    preprocess_log_batch,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "964067ad-2654-4dab-a8fb-92ce482fe04f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_tokenizer = AutoTokenizer.from_pretrained(\"./tokenizers/log_tokenizer_from_old_large/\")\n",
    "log_tokenizer_w_n = AutoTokenizer.from_pretrained(\"./tokenizers/log_tokenizer_from_old_without_numbers/\")\n",
    "batch_size=16  # change to 16 for full training\n",
    "encoder_max_length=180\n",
    "decoder_max_length=180\n",
    "\n",
    "def process_data_to_model_inputs(batch):\n",
    "    # tokenize the inputs and labels\n",
    "    inputs = log_tokenizer_w_n(batch[\"input\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
    "    outputs = log_tokenizer_w_n(batch[\"summary\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
    "\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
    "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
    "    batch[\"labels\"] = outputs.input_ids.copy()\n",
    "\n",
    "    # because BERT automatically shifts the labels, the labels correspond exactly to `decoder_input_ids`. \n",
    "    # We have to make sure that the PAD token is ignored\n",
    "    batch[\"labels\"] = [[-100 if token == log_tokenizer_w_n.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e5d396f-5e22-472c-babc-352ac0945a89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'decoder_input_ids', 'decoder_attention_mask', 'labels'],\n",
       "    num_rows: 9584\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.map(\n",
    "    process_data_to_model_inputs, \n",
    "    batched=True, \n",
    "    batch_size=batch_size, \n",
    "    remove_columns=[\"input\", \"summary\"]\n",
    ")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52e6be99-b353-49d8-be8a-1d7fd126bae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9328aff9-e1fe-44b5-8a19-dbf7ede9b900",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "eval_dataset = eval_dataset.map(\n",
    "    process_data_to_model_inputs, \n",
    "    batched=True, \n",
    "    batch_size=batch_size, \n",
    "    remove_columns=[\"input\", \"summary\"]\n",
    ")\n",
    "\n",
    "eval_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bccd76b-8250-41bc-8837-a41ea0277a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.3,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.3,\n",
       "  \"hidden_size\": 128,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 512,\n",
       "  \"is_only_mlm\": false,\n",
       "  \"is_unilog\": true,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.31.0.dev0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 4075\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_MAX_LENGTH = 180\n",
    "log_tokenizer_w_n = AutoTokenizer.from_pretrained(\"./tokenizers/log_tokenizer_from_old_without_numbers/\", model_max_length=MODEL_MAX_LENGTH, padding=True)\n",
    "#Unilog元論文の実験に準拠\n",
    "#https://arxiv.org/pdf/2112.03159.pdf\n",
    "unilogConfig= BertConfig(\n",
    "    is_unilog=True,\n",
    "    attention_probs_dropout_prob=0.3,\n",
    "    hidden_dropout_prob=0.3,\n",
    "    num_attention_heads=4,\n",
    "    hidden_size=128,\n",
    "    intermediate_size=512,\n",
    "    vocab_size=log_tokenizer_w_n.vocab_size,\n",
    "    num_hidden_layers=3\n",
    ")\n",
    "unilogConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dd962f7-93dd-458d-913e-eb54ca64c6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nとりあえずUnlogモデルをBERTの派生じゃなくて, 一から作る必要がある\\n\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "とりあえずUnlogモデルをBERTの派生じゃなくて, 一から作る必要がある\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad20c5e9-c326-4457-98c7-c198adbc2f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hf_transformers.src.transformers.models.encoder_decoder import EncoderDecoderConfig, EncoderDecoderModel\n",
    "config_encoder = unilogConfig\n",
    "config_decoder = BertConfig(\n",
    "    is_unilog=True,\n",
    "    attention_probs_dropout_prob=0.3,\n",
    "    hidden_dropout_prob=0.3,\n",
    "    num_attention_heads=4,\n",
    "    hidden_size=128,\n",
    "    intermediate_size=512,\n",
    "    vocab_size=log_tokenizer_w_n.vocab_size,\n",
    "    num_hidden_layers=3,\n",
    "    is_decoder=True,\n",
    "    # add_cross_attention=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8d4cd64-f7c3-46ee-b27b-240cb9dd6bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ./logdata/unilog_pretrain_preln_on_attentions_0/ and are newly initialized: ['bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.logact.linear.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.logact.linear.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.logact.linear.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.logact.linear.weight', 'bert.encoder.layer.2.crossattention.output.logact.linear.bias', 'bert.encoder.layer.2.crossattention.output.logact.linear.weight', 'bert.encoder.layer.1.crossattention.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.query.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at ./logdata/unilog_pretrain_preln_on_attentions_0/ and are newly initialized: ['bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.logact.linear.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.logact.linear.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.logact.linear.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.logact.linear.weight', 'bert.encoder.layer.2.crossattention.output.logact.linear.bias', 'bert.encoder.layer.2.crossattention.output.logact.linear.weight', 'bert.encoder.layer.1.crossattention.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.query.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoderModel(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(4075, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "            (output): UnilogBertSelfOutput(\n",
       "              (logact): LogACT(\n",
       "                (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "                (silu): SiLU()\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): BertAttention(\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "            (output): UnilogBertSelfOutput(\n",
       "              (logact): LogACT(\n",
       "                (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "                (silu): SiLU()\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): UnilogBertOutput(\n",
       "            (logact): LogACT(\n",
       "              (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "              (silu): SiLU()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "            (output): UnilogBertSelfOutput(\n",
       "              (logact): LogACT(\n",
       "                (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "                (silu): SiLU()\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): BertAttention(\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "            (output): UnilogBertSelfOutput(\n",
       "              (logact): LogACT(\n",
       "                (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "                (silu): SiLU()\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): UnilogBertOutput(\n",
       "            (logact): LogACT(\n",
       "              (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "              (silu): SiLU()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "            (output): UnilogBertSelfOutput(\n",
       "              (logact): LogACT(\n",
       "                (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "                (silu): SiLU()\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): BertAttention(\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "            (output): UnilogBertSelfOutput(\n",
       "              (logact): LogACT(\n",
       "                (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "                (silu): SiLU()\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): UnilogBertOutput(\n",
       "            (logact): LogACT(\n",
       "              (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "              (silu): SiLU()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): BertLMHeadModel(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(4075, 128, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 128)\n",
       "        (token_type_embeddings): Embedding(2, 128)\n",
       "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "              (output): UnilogBertSelfOutput(\n",
       "                (logact): LogACT(\n",
       "                  (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "                  (silu): SiLU()\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "              (output): UnilogBertSelfOutput(\n",
       "                (logact): LogACT(\n",
       "                  (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "                  (silu): SiLU()\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): UnilogBertOutput(\n",
       "              (logact): LogACT(\n",
       "                (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "                (silu): SiLU()\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "              (output): UnilogBertSelfOutput(\n",
       "                (logact): LogACT(\n",
       "                  (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "                  (silu): SiLU()\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "              (output): UnilogBertSelfOutput(\n",
       "                (logact): LogACT(\n",
       "                  (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "                  (silu): SiLU()\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): UnilogBertOutput(\n",
       "              (logact): LogACT(\n",
       "                (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "                (silu): SiLU()\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "              (output): UnilogBertSelfOutput(\n",
       "                (logact): LogACT(\n",
       "                  (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "                  (silu): SiLU()\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "              (output): UnilogBertSelfOutput(\n",
       "                (logact): LogACT(\n",
       "                  (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "                  (silu): SiLU()\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): UnilogBertOutput(\n",
       "              (logact): LogACT(\n",
       "                (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "                (silu): SiLU()\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): UnilogBertPredictionHeadTransform(\n",
       "          (logact): LogACT(\n",
       "            (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (silu): SiLU()\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=128, out_features=4075, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"./logdata/unilog_pretrain_preln_on_attentions_0/\"\n",
    "unilog2unilog = EncoderDecoderModel.from_encoder_decoder_pretrained(model_path, model_path, encoder_config=unilogConfig, decoder_config=unilogConfig)\n",
    "unilog2unilog.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7db69890-00ab-4b97-b37a-3f6300d32278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unilog2unilog.config.to_json_file(\"./logdata/unilog_summary/checkpoint-64/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5bb2b43-252b-4861-b39e-421343bb956c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#WARNING\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03d780b9-0d8b-4466-8a5c-847e3a55f8b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set special tokens\n",
    "# BERTのトークナイザのCLSとSEPをそれぞれBOSとEOSに\n",
    "unilog2unilog.config.decoder_start_token_id = log_tokenizer_w_n.cls_token_id\n",
    "unilog2unilog.config.eos_token_id = log_tokenizer_w_n.sep_token_id\n",
    "unilog2unilog.config.pad_token_id = log_tokenizer_w_n.pad_token_id\n",
    "\n",
    "# sensible parameters for beam search\n",
    "unilog2unilog.config.vocab_size = unilog2unilog.config.decoder.vocab_size\n",
    "unilog2unilog.config.max_length = 181\n",
    "unilog2unilog.config.min_length = 5\n",
    "unilog2unilog.config.no_repeat_ngram_size = 2\n",
    "unilog2unilog.config.early_stopping = True\n",
    "unilog2unilog.config.length_penalty = 2.0\n",
    "unilog2unilog.config.num_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5e97cdc-d0af-4035-be87-59b2d3fdd860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "rouge = datasets.load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = log_tokenizer_w_n.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = log_tokenizer_w_n.pad_token_id\n",
    "    label_str = log_tokenizer_w_n.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\"])[\"rouge1\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge1_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge1_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge1_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9af34ae4-b0d8-49f6-a68a-6a03a3231ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hf_transformers/src/transformers/optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "/home/hf_transformers/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py:654: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 1:05:25, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1 Precision</th>\n",
       "      <th>Rouge1 Recall</th>\n",
       "      <th>Rouge1 Fmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.109700</td>\n",
       "      <td>7.962016</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.300600</td>\n",
       "      <td>0.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7.420300</td>\n",
       "      <td>7.664610</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.301400</td>\n",
       "      <td>0.024900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>7.619200</td>\n",
       "      <td>7.506829</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.312300</td>\n",
       "      <td>0.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>7.354100</td>\n",
       "      <td>7.449481</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>7.455700</td>\n",
       "      <td>7.405128</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.016200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>7.431900</td>\n",
       "      <td>7.365011</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.020600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>7.300300</td>\n",
       "      <td>7.331917</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>7.300555</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.248700</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>7.131200</td>\n",
       "      <td>7.269632</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.312600</td>\n",
       "      <td>0.026100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>6.994700</td>\n",
       "      <td>7.243221</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.337100</td>\n",
       "      <td>0.028200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>7.033500</td>\n",
       "      <td>7.222153</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.337100</td>\n",
       "      <td>0.028200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>7.180900</td>\n",
       "      <td>7.203233</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.337800</td>\n",
       "      <td>0.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>6.751100</td>\n",
       "      <td>7.188084</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.337600</td>\n",
       "      <td>0.028200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>7.040800</td>\n",
       "      <td>7.179607</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.327900</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>7.222900</td>\n",
       "      <td>7.172979</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.337200</td>\n",
       "      <td>0.028200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>7.118100</td>\n",
       "      <td>7.169238</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.337300</td>\n",
       "      <td>0.028200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hf_transformers/src/transformers/generation/utils.py:1260: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  \"You have modified the pretrained model configuration to control generation. This is a\"\n",
      "/home/hf_transformers/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py:654: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "/home/hf_transformers/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py:654: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "/home/hf_transformers/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py:654: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=64, training_loss=7.3194515109062195, metrics={'train_runtime': 3925.9268, 'train_samples_per_second': 0.261, 'train_steps_per_second': 0.016, 'total_flos': 2479077826560.0, 'train_loss': 7.3194515109062195, 'epoch': 0.11})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set training arguments - these params are not really tuned, feel free to change\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./logdata/unilog_summary_exp03\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=2,  # set to 1000 for full training\n",
    "    save_steps=16,  # set to 500 for full training\n",
    "    eval_steps=4,  # set to 8000 for full training\n",
    "    warmup_steps=1,  # set to 2000 for full training\n",
    "    max_steps=64, # delete for full training\n",
    "    overwrite_output_dir=True,\n",
    "    save_total_limit=3,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=unilog2unilog,\n",
    "    tokenizer=log_tokenizer_w_n,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6191446-416d-4c58-91f8-bb7a91d93b70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'summary'],\n",
       "    num_rows: 1198\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataseta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f9009d0-75ce-4bfc-bf58-ba59d3f1d2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = EncoderDecoderModel.from_pretrained(\"./logdata/unilog_summary/checkpoint-64/\")\n",
    "model.to(device)\n",
    "\n",
    "# only use 16 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
    "batch_size = 16  # change to 64 for full evaluation\n",
    "\n",
    "# map data correctly\n",
    "def generate_summary(batch):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    # cut off at BERT max length 512\n",
    "    inputs = log_tokenizer_w_n(batch[\"input\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # all special tokens including will be removed\n",
    "    output_str = log_tokenizer_w_n.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    batch[\"pred\"] = output_str\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78a9cd18-989b-4742-9eec-dbccff8eaf87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1198 [00:00<?, ? examples/s]/home/hf_transformers/src/transformers/generation/utils.py:1357: UserWarning: Using `max_length`'s default (180) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score(precision=0.011634847651113205, recall=0.265060221620865, fmeasure=0.022053094350537643)\n"
     ]
    }
   ],
   "source": [
    "results = test_dataset.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"input\"])\n",
    "\n",
    "pred_str = results[\"pred\"]\n",
    "label_str = results[\"summary\"]\n",
    "\n",
    "rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\"])[\"rouge1\"].mid\n",
    "\n",
    "print(rouge_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "751528d9-1e36-4d1d-bcf0-610666469d44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "results_with_input = test_dataset.map(generate_summary, batched=True, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acb89dbf-a3eb-4610-a887-f8da4e65f3bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ras kernel fatal data t lb error interrupt\n",
      "Sum: error interrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "df_result = results_with_input.to_pandas()\n",
    "print(df_result[\"input\"][50])\n",
    "print(\"Sum:\", df_result[\"summary\"][50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a1dacfa-ebeb-4571-bcdd-96c136197470",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>summary</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info df s fs name system block name system add...</td>\n",
       "      <td>receiving block packet responder terminating r...</td>\n",
       "      <td>block block block info block info info block b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>info df s data node packet responder packet re...</td>\n",
       "      <td>receiving block packet responder terminating r...</td>\n",
       "      <td>block block block info block info info block b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>switch module fan fan speeds</td>\n",
       "      <td>fan speeds</td>\n",
       "      <td>block block block info block info info block b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>play google com open through proxy proxy c se ...</td>\n",
       "      <td>open through proxy bytes sent bytes received c...</td>\n",
       "      <td>block block block info block info info block b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proxy c se cu hk edu hk open through proxy pro...</td>\n",
       "      <td>open through proxy bytes sent bytes received c...</td>\n",
       "      <td>block block block info block info info block b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>switch module fan fan speeds</td>\n",
       "      <td>fan speeds</td>\n",
       "      <td>block block block info block info info block b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>info executor executor finished task in stage ...</td>\n",
       "      <td>running task finished task partition not found...</td>\n",
       "      <td>block block block info block info info block b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>ras kernel info instruction cache parity error...</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>block block block info block info info block b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>proxy c se cu hk edu hk open through proxy pro...</td>\n",
       "      <td>open through proxy bytes sent bytes received c...</td>\n",
       "      <td>block block block info block info info block b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>node status not responding</td>\n",
       "      <td>node status not responding</td>\n",
       "      <td>block block block info block info info block b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input  \\\n",
       "0     info df s fs name system block name system add...   \n",
       "1     info df s data node packet responder packet re...   \n",
       "2                          switch module fan fan speeds   \n",
       "3     play google com open through proxy proxy c se ...   \n",
       "4     proxy c se cu hk edu hk open through proxy pro...   \n",
       "...                                                 ...   \n",
       "1193                       switch module fan fan speeds   \n",
       "1194  info executor executor finished task in stage ...   \n",
       "1195  ras kernel info instruction cache parity error...   \n",
       "1196  proxy c se cu hk edu hk open through proxy pro...   \n",
       "1197                         node status not responding   \n",
       "\n",
       "                                                summary  \\\n",
       "0     receiving block packet responder terminating r...   \n",
       "1     receiving block packet responder terminating r...   \n",
       "2                                            fan speeds   \n",
       "3     open through proxy bytes sent bytes received c...   \n",
       "4     open through proxy bytes sent bytes received c...   \n",
       "...                                                 ...   \n",
       "1193                                         fan speeds   \n",
       "1194  running task finished task partition not found...   \n",
       "1195           instruction cache parity error corrected   \n",
       "1196  open through proxy bytes sent bytes received c...   \n",
       "1197                         node status not responding   \n",
       "\n",
       "                                                   pred  \n",
       "0     block block block info block info info block b...  \n",
       "1     block block block info block info info block b...  \n",
       "2     block block block info block info info block b...  \n",
       "3     block block block info block info info block b...  \n",
       "4     block block block info block info info block b...  \n",
       "...                                                 ...  \n",
       "1193  block block block info block info info block b...  \n",
       "1194  block block block info block info info block b...  \n",
       "1195  block block block info block info info block b...  \n",
       "1196  block block block info block info info block b...  \n",
       "1197  block block block info block info info block b...  \n",
       "\n",
       "[1198 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3973a951-f5d7-4362-89c1-5cb46c0793e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        INFO dfs.DataNode$DataXceiver : Receiving bloc...\n",
       "1        INFO dfs.DataNode$DataXceiver : Receiving bloc...\n",
       "2        INFO dfs.DataNode$DataXceiver : Receiving bloc...\n",
       "3        INFO dfs.DataNode$DataXceiver : Receiving bloc...\n",
       "4        INFO dfs.DataNode$PacketResponder : PacketResp...\n",
       "                               ...                        \n",
       "11975       INFO storage.BlockManager : Removing RDD 12744\n",
       "11976       INFO storage.BlockManager : Removing RDD 12740\n",
       "11977       INFO storage.BlockManager : Removing RDD 12736\n",
       "11978       INFO storage.BlockManager : Removing RDD 12732\n",
       "11979       INFO storage.BlockManager : Removing RDD 12728\n",
       "Name: input, Length: 11980, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary[\"input\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda42d26-e238-4feb-a0d9-f35f66a75bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
