{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "848dabf6-49fa-411b-9477-4bce9ca90d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "import wordninja\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import json\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, default_data_collator, get_scheduler\n",
    "from hf_transformers.src.transformers.models.bert.configuration_bert import BertConfig\n",
    "from hf_transformers.src.transformers.models.bert.modeling_bert import BertForPreTraining\n",
    "from torch.utils.data import DataLoader\n",
    "from hf_transformers.src.transformers.models.bert.modeling_bert import BertForSequenceClassification, BertModel\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import collections\n",
    "\n",
    "\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bcd061c-2322-4fdd-83f8-8b331712829e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#WARNING\n",
    "#cacheディレクトリの指定は絶対マウント先のフォルダにするように\n",
    "#そうしないとdockerイメージを管理している研究室サーバーのルートディレクトリ(/)がパンパンになってしまう\n",
    "#/が容量オーバーすると何も動かなくなって他の人に迷惑\n",
    "!export HF_DATASETS_CACHE=\"/home/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7afe5ec-0bfb-4a81-ad68-02e9e534b50d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_downsampled = pd.read_csv(\"./logdata/downsampled_anomaly.csv\", usecols=[\"BlockId\", \"Label\", \"log\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4d3cc70-ee9a-4e52-bdc6-07911f8f2657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>BlockId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>081109 203521 145 INFO dfs.DataNode$DataXceive...</td>\n",
       "      <td>blk_-3544583377289625738</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>081109 203521 29 INFO dfs.FSNamesystem: BLOCK*...</td>\n",
       "      <td>blk_-3544583377289625738</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>081109 203522 144 INFO dfs.DataNode$DataXceive...</td>\n",
       "      <td>blk_-3544583377289625738</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>081109 203522 145 INFO dfs.DataNode$DataXceive...</td>\n",
       "      <td>blk_-3544583377289625738</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>081109 203522 147 INFO dfs.DataNode$PacketResp...</td>\n",
       "      <td>blk_-3544583377289625738</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576495</th>\n",
       "      <td>081111 030649 32 INFO dfs.FSNamesystem: BLOCK*...</td>\n",
       "      <td>blk_4241722502979736601</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576496</th>\n",
       "      <td>081110 010143 30 INFO dfs.FSNamesystem: BLOCK*...</td>\n",
       "      <td>blk_2863437573282244260</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576497</th>\n",
       "      <td>081111 040435 33 INFO dfs.FSNamesystem: BLOCK*...</td>\n",
       "      <td>blk_-8441598874045640693</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576498</th>\n",
       "      <td>081111 044332 29 INFO dfs.FSNamesystem: BLOCK*...</td>\n",
       "      <td>blk_795775988001366663</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576499</th>\n",
       "      <td>081110 210122 28 INFO dfs.FSNamesystem: BLOCK*...</td>\n",
       "      <td>blk_3806682485949045504</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      log  \\\n",
       "0       081109 203521 145 INFO dfs.DataNode$DataXceive...   \n",
       "1       081109 203521 29 INFO dfs.FSNamesystem: BLOCK*...   \n",
       "2       081109 203522 144 INFO dfs.DataNode$DataXceive...   \n",
       "3       081109 203522 145 INFO dfs.DataNode$DataXceive...   \n",
       "4       081109 203522 147 INFO dfs.DataNode$PacketResp...   \n",
       "...                                                   ...   \n",
       "576495  081111 030649 32 INFO dfs.FSNamesystem: BLOCK*...   \n",
       "576496  081110 010143 30 INFO dfs.FSNamesystem: BLOCK*...   \n",
       "576497  081111 040435 33 INFO dfs.FSNamesystem: BLOCK*...   \n",
       "576498  081111 044332 29 INFO dfs.FSNamesystem: BLOCK*...   \n",
       "576499  081110 210122 28 INFO dfs.FSNamesystem: BLOCK*...   \n",
       "\n",
       "                         BlockId    Label  \n",
       "0       blk_-3544583377289625738  Anomaly  \n",
       "1       blk_-3544583377289625738  Anomaly  \n",
       "2       blk_-3544583377289625738  Anomaly  \n",
       "3       blk_-3544583377289625738  Anomaly  \n",
       "4       blk_-3544583377289625738  Anomaly  \n",
       "...                          ...      ...  \n",
       "576495   blk_4241722502979736601   Normal  \n",
       "576496   blk_2863437573282244260   Normal  \n",
       "576497  blk_-8441598874045640693   Normal  \n",
       "576498    blk_795775988001366663   Normal  \n",
       "576499   blk_3806682485949045504   Normal  \n",
       "\n",
       "[576500 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "576a568f-b9d5-4da6-86c3-1b67e8342856",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFO dfs.DataNode$DataXceiver : Receiving bloc...</td>\n",
       "      <td>Receiving block src; blockMap updated; Verific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFO dfs.DataNode$DataXceiver : Receiving bloc...</td>\n",
       "      <td>Receiving block src; blockMap updated; Verific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFO dfs.DataNode$DataXceiver : Receiving bloc...</td>\n",
       "      <td>Receiving block src; blockMap updated; Verific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFO dfs.DataNode$DataXceiver : Receiving bloc...</td>\n",
       "      <td>Receiving block src; blockMap updated; Verific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFO dfs.DataNode$PacketResponder : PacketResp...</td>\n",
       "      <td>Receiving block src; blockMap updated; Verific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11975</th>\n",
       "      <td>INFO storage.BlockManager : Removing RDD 12744</td>\n",
       "      <td>Removing RDD;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11976</th>\n",
       "      <td>INFO storage.BlockManager : Removing RDD 12740</td>\n",
       "      <td>Removing RDD;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977</th>\n",
       "      <td>INFO storage.BlockManager : Removing RDD 12736</td>\n",
       "      <td>Removing RDD;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11978</th>\n",
       "      <td>INFO storage.BlockManager : Removing RDD 12732</td>\n",
       "      <td>Removing RDD;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11979</th>\n",
       "      <td>INFO storage.BlockManager : Removing RDD 12728</td>\n",
       "      <td>Removing RDD;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input  \\\n",
       "0      INFO dfs.DataNode$DataXceiver : Receiving bloc...   \n",
       "1      INFO dfs.DataNode$DataXceiver : Receiving bloc...   \n",
       "2      INFO dfs.DataNode$DataXceiver : Receiving bloc...   \n",
       "3      INFO dfs.DataNode$DataXceiver : Receiving bloc...   \n",
       "4      INFO dfs.DataNode$PacketResponder : PacketResp...   \n",
       "...                                                  ...   \n",
       "11975     INFO storage.BlockManager : Removing RDD 12744   \n",
       "11976     INFO storage.BlockManager : Removing RDD 12740   \n",
       "11977     INFO storage.BlockManager : Removing RDD 12736   \n",
       "11978     INFO storage.BlockManager : Removing RDD 12732   \n",
       "11979     INFO storage.BlockManager : Removing RDD 12728   \n",
       "\n",
       "                                                 summary  \n",
       "0      Receiving block src; blockMap updated; Verific...  \n",
       "1      Receiving block src; blockMap updated; Verific...  \n",
       "2      Receiving block src; blockMap updated; Verific...  \n",
       "3      Receiving block src; blockMap updated; Verific...  \n",
       "4      Receiving block src; blockMap updated; Verific...  \n",
       "...                                                  ...  \n",
       "11975                                      Removing RDD;  \n",
       "11976                                      Removing RDD;  \n",
       "11977                                      Removing RDD;  \n",
       "11978                                      Removing RDD;  \n",
       "11979                                      Removing RDD;  \n",
       "\n",
       "[11980 rows x 2 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = pd.read_csv(\"./logdata/log_summary_pairs.csv\", usecols=[\"input\", \"summary\"])\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c7aedb-0533-4876-a02a-a9e10a456fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def log2list(path):\n",
    "#     with open(path, \"r\") as f:\n",
    "#         lines = [line.rstrip(\"\\n\") for line in f]\n",
    "#     return lines\n",
    "\n",
    "# hdfs = log2list(\"./logdata/hdfs/HDFS.log\")\n",
    "# log_label_pairs = {}\n",
    "\n",
    "# df_hdfs_logs = pd.DataFrame({\"log\" : hdfs})\n",
    "# df_hdfs_logs[\"BlockId\"] = df_hdfs_logs[\"log\"].map(lambda line : re.search(r\"blk_[-]*[0-9]+\", line).group(0))\n",
    "# df_hdfs = df_hdfs_anomaly.merge(df_hdfs_logs, how=\"left\", on=[\"BlockId\"])\n",
    "\n",
    "# df_hdfs_without_duplicate = df_hdfs.drop_duplicates([\"BlockId\"])\n",
    "# df_hdfs_without_duplicate.to_csv(\"./logdata/hdfs/df_hdfs_without_duplicate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "363d69cc-7132-4407-a06b-58060eb547be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_hdfs_without_duplicate[\"text\"] = df_hdfs_without_duplicate[\"log\"].map(preprocess_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3accd1b-045a-420c-8771-36d6821747e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.31.0.dev0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9b5954f-230a-4488-b152-aacd7cf29623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#分類と事前学習で異なるトークナイザを利用している？\n",
    "#根拠: 例えばHDFSの異常検知の場合, 異常ラベルはログデータのブロック番号と紐づけられている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "28f44bce-4cfc-497d-927d-ce3ed5949837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#NOTE\n",
    "#ここで記号を区切ってwordninjaで塊除去を行っている\n",
    "#なお, かなり時間がかかるので実行には注意が必要\n",
    "#もう少し賢く書きたかったが, その書き方を思いつく時間とナイーブに実行する時間はどうせ同じぐらいだろう\n",
    "def preprocess_log(text, remove_digits):\n",
    "    text = text.replace('[', \" \")\n",
    "    text = text.replace(\".\", \" \")\n",
    "    text = text.replace(\",\", \" \")\n",
    "    text = text.replace(\":\", \" \")\n",
    "    text = text.replace(\"/\", \" \")\n",
    "    text = text.replace(\";\", \" \")\n",
    "    text = text.replace(\"=\", \" \")\n",
    "    text = text.replace(\"*\", \" \")\n",
    "    text = text.replace(\"_\", \" \")\n",
    "    text = text.replace(\"-\", \" \")\n",
    "    text = text.lower()\n",
    "    text = \" \".join(wordninja.split(text))\n",
    "    remove_num = lambda eg : \" \".join([word for word in eg.split(\" \") if not word.isdigit()])\n",
    "    if remove_digits:\n",
    "        return remove_num(text)\n",
    "    return text;\n",
    "\n",
    "def preprocess_log_batch_hof(remove_digits=True):\n",
    "    def preprocess_log_batch(example):\n",
    "        return {\n",
    "            \"text\": [preprocess_log(l, remove_digits=remove_digits) for l in example[\"log\"]]\n",
    "        }\n",
    "    return preprocess_log_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de78902-9a36-4577-9348-42a7a238d3d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_ad_hdfs = pd.read_csv(\"./logdata/hdfs/hdfs_log_label_pairs.csv\", usecols=[\"log\", \"BlockId\", \"Label\"])\n",
    "# df_hdfs_without_duplicate[\"text\"] = df_hdfs_without_duplicate[\"log\"].map(preprocess_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b85234e-f3b4-4217-a0cd-30408e714cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ダウンサンプリングした\n",
    "# df_ad_hdfs[\"Label\"].value_counts(normalize=True)\n",
    "# df_equal = df_ad_hdfs[df_ad_hdfs[\"Label\"]==\"Anomaly\"]\n",
    "# df_normal_sampled = df_ad_hdfs[df_ad_hdfs[\"Label\"]==\"Normal\"].sample(len(df_equal))\n",
    "# df_equal = pd.concat([df_equal, df_normal_sampled])\n",
    "# df_equal.to_csv(\"./logdata/downsampled_anomaly.csv\")\n",
    "# df_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ccd07a4-ccaa-47e6-b344-bc02610afd2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-a438c5b2cd2acdf4/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n",
      "100%|██████████| 1/1 [00:00<00:00, 589.83it/s]\n",
      "Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-8d2c1362a4f07327/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.88it/s]\n"
     ]
    }
   ],
   "source": [
    "#NOTE\n",
    "#Loading train test dataset used in loglizer here for the sake of fair comparison\n",
    "\n",
    "TEST_DATA_FILE_PATH = \"./logdata/hdfs/loglizer_hdfs_test_data.csv\"\n",
    "TRAIN_DATA_FILE_PATH = \"./logdata/hdfs/df_hdfs_without_duplicate.csv\"\n",
    "\n",
    "\n",
    "dataset_hdfs_test = load_dataset(\"csv\", data_files=TEST_DATA_FILE_PATH)\n",
    "dataset_hdfs_test = dataset_hdfs_test.remove_columns(['Unnamed: 0'])\n",
    "\n",
    "dataset_hdfs_train = load_dataset(\"csv\", data_files=TRAIN_DATA_FILE_PATH)\n",
    "dataset_hdfs_train = dataset_hdfs_train.remove_columns(['Unnamed: 0'])\n",
    "\n",
    "train_valid = dataset_hdfs_train[\"train\"].train_test_split(0.2)\n",
    "train_data = train_valid[\"train\"]\n",
    "eval_dataset = train_valid[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb18d91-4d58-40f3-9ce6-1e633c44eebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal     0.970714\n",
       "Anomaly    0.029286\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.to_pandas()[\"Label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13bd3736-6b79-4b2e-af00-eefba77def72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['BlockId', 'Label', 'log'],\n",
       "        num_rows: 575061\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_hdfs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf42deeb-37b9-43fa-be99-9ef918b76e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATA_FILE_PATH, usecols=[\"BlockId\", \"Label\", \"log\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f04908e-47e3-4643-86a7-f5a1c86272fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#NOTE\n",
    "#Removing all test data here\n",
    "\n",
    "df_test = pd.read_csv(TEST_DATA_FILE_PATH, usecols=[\"log\", \"BlockId\", \"Label\"])\n",
    "test_blk_ids = list(df_test[\"BlockId\"])\n",
    "df_clean = df_train[~df_train[\"BlockId\"].isin(test_blk_ids)]\n",
    "df_clean.to_csv(\"./logdata/hdfs/downsampled_anomaly_without_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf549ef3-4376-4c63-b884-5e0220d567d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-2a9c33563e8a79ae/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loading larger dataset that does not contain test data used in loglizer \n",
    "datased_ad_hdfs = load_dataset(\"csv\", data_files=\"./logdata/hdfs/anomaly_without_test.csv\")\n",
    "datased_ad_hdfs = datased_ad_hdfs[\"train\"].train_test_split(0.2)\n",
    "datased_ad_hdfs = datased_ad_hdfs.remove_columns(['Unnamed: 0'])\n",
    "\n",
    "train_data = datased_ad_hdfs[\"train\"]\n",
    "eval_dataset = datased_ad_hdfs[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9732b8c1-9752-440e-a0f5-3add2c0389a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    }
   ],
   "source": [
    "train_data = train_data.map(\n",
    "    preprocess_log_batch_hof(remove_digits=False),\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f09fe6e7-8c2a-414a-a639-32f52ae288ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    }
   ],
   "source": [
    "eval_dataset = eval_dataset.map(\n",
    "    preprocess_log_batch_hof(remove_digits=False),\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "964067ad-2654-4dab-a8fb-92ce482fe04f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_tokenizer = AutoTokenizer.from_pretrained(\"./tokenizers/log_tokenizer_from_old_large/\")\n",
    "log_tokenizer_w_n = AutoTokenizer.from_pretrained(\"./tokenizers/log_tokenizer_from_old_without_numbers/\")\n",
    "\n",
    "batch_size=16  # change to 16 for full training\n",
    "\n",
    "def process_data_to_model_inputs_from_target(target_tokenizer, target_tag=\"log\"):\n",
    "    def process_data_to_model_inputs(batch):\n",
    "        # tokenize the inputs and labels\n",
    "        # NOTE \n",
    "        # x != \"Normal\"の符号を==にしてしまっていたのがミスの原因\n",
    "        batch[\"labels\"] = list(map(lambda x : int(x != \"Normal\"), batch[\"Label\"]))\n",
    "\n",
    "        return target_tokenizer(batch[target_tag], padding=\"max_length\", truncation=True, max_length=180)\n",
    "    return process_data_to_model_inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e5d396f-5e22-472c-babc-352ac0945a89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 456872\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_data = train_data.map(\n",
    "    process_data_to_model_inputs_from_target(log_tokenizer, target_tag=\"text\"), \n",
    "    batched=True, \n",
    "    batch_size=10000, \n",
    "    remove_columns=['log', 'BlockId', 'Label', 'text']\n",
    ")\n",
    "tokenized_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3f40b18-0b59-46f9-a867-90e9d6cab949",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'081110 223339 15898 info df s data node data x ce iver receiving block b lk 1029163488700913789 s rc 10 250 10 176 59011 de st 10 250 10 176 50010'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "599075fe-0458-48ad-b8ff-1111472a2aef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 081110 223339 15898 info df s data node data x ce iver receiving block b lk 1029163488700913789 s rc 10 250 10 176 59011 de st 10 250 10 176 50010 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_tokenizer.decode(tokenized_train_data[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52e6be99-b353-49d8-be8a-1d7fd126bae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_train_data.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9767ba64-f052-4ddf-85a1-07c2e4c0cf96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# small_train_dataset = tokenized_train_data.shuffle(seed=42).select(range(1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9328aff9-e1fe-44b5-8a19-dbf7ede9b900",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    }
   ],
   "source": [
    "eval_dataset = eval_dataset.map(\n",
    "    process_data_to_model_inputs_from_target(log_tokenizer, target_tag=\"text\"), \n",
    "    batched=True, \n",
    "    batch_size=10000, \n",
    "    remove_columns=['log', 'BlockId', 'Label', 'text']\n",
    ")\n",
    "\n",
    "eval_dataset.set_format(type=\"torch\")\n",
    "# small_eval_dataset = eval_dataset.shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "179f9999-de31-49d3-9c59-ad65d1504fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-a438c5b2cd2acdf4/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 654.64it/s]\n",
      "\n",
      "Map:   0%|          | 0/3971 [00:00<?, ? examples/s]\u001b[A\n",
      "Map:  25%|██▌       | 1000/3971 [00:01<00:03, 959.13 examples/s]\u001b[A\n",
      "Map:  50%|█████     | 2000/3971 [00:02<00:02, 962.84 examples/s]\u001b[A\n",
      "Map:  76%|███████▌  | 3000/3971 [00:03<00:01, 961.74 examples/s]\u001b[A\n",
      "Map: 100%|██████████| 3971/3971 [00:04<00:00, 961.43 examples/s]\u001b[A\n",
      "                                                                \u001b[A\n",
      "Map:   0%|          | 0/3971 [00:00<?, ? examples/s]\u001b[A\n",
      "Map:  10%|▉         | 384/3971 [00:00<00:00, 3749.77 examples/s]\u001b[A\n",
      "Map:  21%|██        | 816/3971 [00:00<00:00, 3951.03 examples/s]\u001b[A\n",
      "Map:  31%|███       | 1232/3971 [00:00<00:00, 3953.76 examples/s]\u001b[A\n",
      "Map:  43%|████▎     | 1712/3971 [00:00<00:00, 4212.38 examples/s]\u001b[A\n",
      "Map:  54%|█████▍    | 2160/3971 [00:00<00:00, 4244.22 examples/s]\u001b[A\n",
      "Map:  65%|██████▌   | 2592/3971 [00:00<00:00, 4199.31 examples/s]\u001b[A\n",
      "Map:  78%|███████▊  | 3104/3971 [00:00<00:00, 4464.42 examples/s]\u001b[A\n",
      "Map:  89%|████████▉ | 3552/3971 [00:00<00:00, 4392.74 examples/s]\u001b[A\n",
      "                                                                 \u001b[A"
     ]
    }
   ],
   "source": [
    "dataset_hdfs_test = load_dataset(\"csv\", data_files=TEST_DATA_FILE_PATH)\n",
    "dataset_hdfs_test = dataset_hdfs_test.remove_columns(['Unnamed: 0'])\n",
    "test_dataset = dataset_hdfs_test.map(\n",
    "    preprocess_log_batch_hof(remove_digits=True),\n",
    "    batched=True,\n",
    ")[\"train\"]\n",
    "\n",
    "tokenized_test_dataset = test_dataset.map(\n",
    "    process_data_to_model_inputs_from_target(log_tokenizer_w_n, target_tag=\"text\"),\n",
    "    batched=True, \n",
    "    batch_size=batch_size, \n",
    "    remove_columns=['log', 'BlockId', 'Label', 'text']\n",
    ")\n",
    "\n",
    "\n",
    "tokenized_test_dataset.set_format(type=\"torch\")\n",
    "test_dataloader = DataLoader(tokenized_test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "94ed9f0b-25a8-44bd-b493-80602ef3e0a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = test_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d1f0a2a0-2984-4013-a77b-e43c8c74903d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test_anomaly = df_test[df_test.Label!=\"Normal\"]\n",
    "df_test_normal = df_test[df_test.Label==\"Normal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a797349b-4512-4abd-abd4-8b5a99299773",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'081109 204352 33 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /user/root/rand/_temporary/_task_200811092030_0001_m_000345_0/part-00345. blk_-8975646672319015268'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_normal.iloc[963][\"log\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f77b203b-3992-4ab4-aad6-1aea1bce6edb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'081109 204346 29 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /user/root/rand/_temporary/_task_200811092030_0001_m_000240_0/part-00240. blk_8522440494057928612'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_anomaly[\"log\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3326fb74-e3e3-4bdf-9f89-ea06203e5b53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test_anomaly[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4cca5a2e-5a1d-4927-aa1a-cff982db8263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fasttextでログをベクトル化\n",
    "def vectorize_log(target_model):\n",
    "    def vectorize_log_helper(input_log):\n",
    "        v = np.zeros(100, dtype=float)\n",
    "\n",
    "        for w in input_log.split():\n",
    "            v += target_model[w] \n",
    "        return v / len(input_log.split())\n",
    "    return vectorize_log_helper\n",
    "\n",
    "#ref: https://necromuralist.github.io/Neurotic-Networking/posts/nlp/machine-translation-k-nearest-neighbors/index.html\n",
    "\n",
    "def cosine_similarity(vector_1: np.ndarray, vector_2: np.ndarray) -> float:\n",
    "    \"\"\"Calculates the similarity between two vectors\n",
    "\n",
    "    Args:\n",
    "     vector_1: array to compare\n",
    "     vector_2: array to compare to vector_1\n",
    "\n",
    "    Returns:\n",
    "     cosine similarity between the two vectors\n",
    "    \"\"\"\n",
    "    return np.dot(vector_1, vector_2)/(np.linalg.norm(vector_1) *\n",
    "                                          np.linalg.norm(vector_2))\n",
    "\n",
    "#fasttextでベクトル化したログデータのうち,k近傍のベクトルを得ている\n",
    "#なお, 論文(https://arxiv.org/abs/2305.15778)ではユークリッド距離と時系列を考慮しているが, 単純化のためここでは単なるコサイン類似度を利用\n",
    "def nearest_neighbor(v, candidates, k=1):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      - v, the vector you are going find the nearest neighbor for\n",
    "      - candidates: a set of vectors where we will find the neighbors\n",
    "      - k: top k nearest neighbors to find\n",
    "    Output:\n",
    "      - k_idx: the indices of the top k closest vectors in sorted form\n",
    "    \"\"\"\n",
    "    # cosine_similarities = [cosine_similarity(v, row) for row in candidates]\n",
    "\n",
    "    # for each candidate vector...\n",
    "    #for row in candidates:\n",
    "    #    # get the cosine similarity\n",
    "    #    cos_similarity = cosine_similarity(v, row)\n",
    "    #\n",
    "    #    # append the similarity to the list\n",
    "    #    similarity_l.append(cos_similarity)\n",
    "\n",
    "    # sort the similarity list and get the indices of the sorted list\n",
    "    # sorted_ids = numpy.argsort(similarity_l)\n",
    "\n",
    "    # get the indices of the k most similar candidate vectors\n",
    "    # k_idx = sorted_ids[-k:]\n",
    "    ### END CODE HERE ###\n",
    "    return np.argsort([cosine_similarity(v, row) for row in candidates])[-k:]\n",
    "\n",
    "def show_current_log(idx):\n",
    "    for column in df_summary.columns:\n",
    "        if column != \"log_vector\":\n",
    "            print(f\"{column}: \", df_summary.iloc[idx, :][column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "557d943e-3fd2-4296-ae85-e1dc5bbbf40c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"pooler_output\"].squeeze().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d3371a7f-aab5-456a-87ba-50e87633e027",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'081109 204208 26 info df s fs name system block name system allocate block user root rand temporary task 200811092030 0001 m 000043 0 part 00043 b lk 942782950815104487'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_normal[\"text\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fca89646-0834-4727-8abe-1b82ceb1d290",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 081109 204217 33 info df s fs name system block name system allocate block user root rand temporary task 200811092030 0001 m 000390 0 part 00390 b lk 4575784335805628598 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_tokenizer.decode(tokenized_test_dataset[100][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8145d2-0dde-46ec-b69d-33667bdd8880",
   "metadata": {},
   "source": [
    "# ここまで"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9dbe9e91-5f3a-491e-86c0-c399590276db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.960463\n",
       "1    0.039537\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader.dataset.to_pandas()[\"labels\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3afb3d03-0809-4a5a-a602-9e34ab4a3d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_train_data, shuffle=True, batch_size=32)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a74cb09-959d-4d89-9e3d-8f7c6c9b3448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.970782\n",
       "1    0.029218\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset.to_pandas()[\"labels\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ac61b05-90b9-4047-b103-b7621c3924f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "aa1f3081-01e1-49f7-9ba1-d8f4998db325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['log', 'summary'],\n",
       "    num_rows: 11980\n",
       "})"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2b017-6c49-4074-a81f-528d94b945cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3dd962f7-93dd-458d-913e-eb54ca64c6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./logdata/unilog_pretrain_with_numbers_12_layers_2/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "unilogConfigmodel = BertForSequenceClassification.from_pretrained(\"./logdata/unilog_pretrain_with_numbers_12_layers_2/\", num_labels=2).to(device)\n",
    "optimizer = AdamW(unilogConfigmodel.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5e97cdc-d0af-4035-be87-59b2d3fdd860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e5a3734-3d7f-4a53-91a1-992ebe3e11d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14278"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_training_steps // 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2c2fa4a-5b24-4887-a2d3-19795e2e7ead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a385026-11b3-4951-8684-8e5234fbcffe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAVE_NAME = \"./logdata/log_anomaly_with_numbers_no_downsampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d53f7-35ec-4b50-9a0b-67187a63dc73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_steps = 0\n",
    "\n",
    "save_steps = 1000\n",
    "\n",
    "best_f1 = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    unilogConfigmodel.train()\n",
    "    pbar = tqdm(train_dataloader)\n",
    "    for batch in train_dataloader:\n",
    "        train_steps += 1\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = unilogConfigmodel(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        pbar.update(1)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        if train_steps % save_steps == 0:\n",
    "            pbar.write(f\"Loss:{loss}\")\n",
    "            #TODO \n",
    "            unilogConfigmodel.save_pretrained(f\"{SAVE_NAME}_{train_steps}\")\n",
    "    import evaluate\n",
    "\n",
    "    metric_acc = evaluate.load(\"accuracy\")\n",
    "    metric_f1 = evaluate.load(\"f1\")\n",
    "    metric_precision = evaluate.load(\"precision\")\n",
    "    metric_recall = evaluate.load(\"recall\")\n",
    "\n",
    "    unilogConfigmodel.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = unilogConfigmodel(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric_acc.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "        metric_f1.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "        metric_precision.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "        metric_recall.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "    pbar.write(str(metric_acc.compute()))\n",
    "    pbar.write(str(metric_precision.compute()))\n",
    "    pbar.write(str(metric_recall.compute()))\n",
    "    \n",
    "    curr_f1_score = metric_f1.compute()[\"f1\"]\n",
    "    prev_f1_score = best_f1\n",
    "    pbar.write(f\"F1: {str(curr_f1_score)}\")\n",
    "    if (curr_f1_score > prev_f1_score):\n",
    "        best_f1 = max(best_f1, curr_f1_score)\n",
    "        unilogConfigmodel.save_pretrained(f\"./{SAVE_NAME}_best\")\n",
    "\n",
    "\n",
    "train_dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3902c14-1d0d-44e8-9769-6f5ba6e68446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 3971\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fae2252b-f4c3-4980-a14b-f6e7a6c6991a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/497 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 8/497 [00:00<00:06, 75.56it/s]\u001b[A\n",
      "  3%|▎         | 16/497 [00:00<00:06, 76.37it/s]\u001b[A\n",
      "  5%|▍         | 24/497 [00:00<00:06, 76.70it/s]\u001b[A\n",
      "  6%|▋         | 32/497 [00:00<00:06, 76.29it/s]\u001b[A\n",
      "  8%|▊         | 40/497 [00:00<00:05, 76.47it/s]\u001b[A\n",
      " 10%|▉         | 48/497 [00:00<00:05, 76.63it/s]\u001b[A\n",
      " 11%|█▏        | 56/497 [00:00<00:05, 76.78it/s]\u001b[A\n",
      " 13%|█▎        | 64/497 [00:00<00:05, 76.86it/s]\u001b[A\n",
      " 14%|█▍        | 72/497 [00:00<00:05, 76.93it/s]\u001b[A\n",
      " 16%|█▌        | 80/497 [00:01<00:05, 76.98it/s]\u001b[A\n",
      " 18%|█▊        | 88/497 [00:01<00:05, 76.85it/s]\u001b[A\n",
      " 19%|█▉        | 96/497 [00:01<00:05, 75.59it/s]\u001b[A\n",
      " 21%|██        | 104/497 [00:01<00:05, 75.79it/s]\u001b[A\n",
      " 23%|██▎       | 112/497 [00:01<00:05, 75.93it/s]\u001b[A\n",
      " 24%|██▍       | 120/497 [00:01<00:04, 76.05it/s]\u001b[A\n",
      " 26%|██▌       | 128/497 [00:01<00:04, 76.18it/s]\u001b[A\n",
      " 27%|██▋       | 136/497 [00:01<00:04, 76.20it/s]\u001b[A\n",
      " 29%|██▉       | 144/497 [00:01<00:04, 76.23it/s]\u001b[A\n",
      " 31%|███       | 152/497 [00:01<00:04, 76.29it/s]\u001b[A\n",
      " 32%|███▏      | 160/497 [00:02<00:04, 76.29it/s]\u001b[A\n",
      " 34%|███▍      | 168/497 [00:02<00:04, 76.32it/s]\u001b[A\n",
      " 35%|███▌      | 176/497 [00:02<00:04, 76.35it/s]\u001b[A\n",
      " 37%|███▋      | 184/497 [00:02<00:04, 76.40it/s]\u001b[A\n",
      " 39%|███▊      | 192/497 [00:02<00:03, 76.40it/s]\u001b[A\n",
      " 40%|████      | 200/497 [00:02<00:03, 76.45it/s]\u001b[A\n",
      " 42%|████▏     | 208/497 [00:02<00:03, 76.44it/s]\u001b[A\n",
      " 43%|████▎     | 216/497 [00:02<00:03, 76.43it/s]\u001b[A\n",
      " 45%|████▌     | 224/497 [00:02<00:03, 76.41it/s]\u001b[A\n",
      " 47%|████▋     | 232/497 [00:03<00:03, 76.42it/s]\u001b[A\n",
      " 48%|████▊     | 240/497 [00:03<00:03, 75.11it/s]\u001b[A\n",
      " 50%|████▉     | 248/497 [00:03<00:03, 73.76it/s]\u001b[A\n",
      " 52%|█████▏    | 256/497 [00:03<00:03, 74.50it/s]\u001b[A\n",
      " 53%|█████▎    | 264/497 [00:03<00:03, 75.07it/s]\u001b[A\n",
      " 55%|█████▍    | 272/497 [00:03<00:02, 75.41it/s]\u001b[A\n",
      " 56%|█████▋    | 280/497 [00:03<00:02, 75.70it/s]\u001b[A\n",
      " 58%|█████▊    | 288/497 [00:03<00:02, 73.01it/s]\u001b[A\n",
      " 60%|█████▉    | 296/497 [00:03<00:02, 73.08it/s]\u001b[A\n",
      " 61%|██████    | 304/497 [00:04<00:02, 74.00it/s]\u001b[A\n",
      " 63%|██████▎   | 312/497 [00:04<00:02, 73.78it/s]\u001b[A\n",
      " 64%|██████▍   | 320/497 [00:04<00:02, 73.60it/s]\u001b[A\n",
      " 66%|██████▌   | 328/497 [00:04<00:02, 73.49it/s]\u001b[A\n",
      " 68%|██████▊   | 336/497 [00:04<00:02, 73.41it/s]\u001b[A\n",
      " 69%|██████▉   | 344/497 [00:04<00:02, 73.35it/s]\u001b[A\n",
      " 71%|███████   | 352/497 [00:04<00:01, 73.26it/s]\u001b[A\n",
      " 72%|███████▏  | 360/497 [00:04<00:01, 73.48it/s]\u001b[A\n",
      " 74%|███████▍  | 368/497 [00:04<00:01, 73.49it/s]\u001b[A\n",
      " 76%|███████▌  | 376/497 [00:04<00:01, 73.74it/s]\u001b[A\n",
      " 77%|███████▋  | 384/497 [00:05<00:01, 74.09it/s]\u001b[A\n",
      " 79%|███████▉  | 392/497 [00:05<00:01, 73.89it/s]\u001b[A\n",
      " 80%|████████  | 400/497 [00:05<00:01, 73.69it/s]\u001b[A\n",
      " 82%|████████▏ | 408/497 [00:05<00:01, 73.61it/s]\u001b[A\n",
      " 84%|████████▎ | 416/497 [00:05<00:01, 73.16it/s]\u001b[A\n",
      " 85%|████████▌ | 424/497 [00:05<00:00, 73.21it/s]\u001b[A\n",
      " 87%|████████▋ | 432/497 [00:05<00:00, 73.22it/s]\u001b[A\n",
      " 89%|████████▊ | 440/497 [00:05<00:00, 73.06it/s]\u001b[A\n",
      " 90%|█████████ | 448/497 [00:05<00:00, 74.15it/s]\u001b[A\n",
      " 92%|█████████▏| 456/497 [00:06<00:00, 74.95it/s]\u001b[A\n",
      " 93%|█████████▎| 464/497 [00:06<00:00, 75.53it/s]\u001b[A\n",
      " 95%|█████████▍| 472/497 [00:06<00:00, 75.91it/s]\u001b[A\n",
      " 97%|█████████▋| 480/497 [00:06<00:00, 75.80it/s]\u001b[A\n",
      " 98%|█████████▊| 488/497 [00:06<00:00, 76.10it/s]\u001b[A\n",
      "100%|██████████| 497/497 [00:06<00:00, 75.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9604633593553261}\n",
      "{'f1': 0.0}\n",
      "{'precision': 0.0}\n",
      "{'recall': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_f1 = evaluate.load(\"f1\")\n",
    "metric_precision = evaluate.load(\"precision\")\n",
    "metric_recall = evaluate.load(\"recall\")\n",
    "\n",
    "unilogBestModel = BertForSequenceClassification.from_pretrained(\"./logdata/log_anomaly_with_numbers_no_downsampling_15000/\", num_labels=2).to(device)\n",
    "unilogBestModel.eval()\n",
    "\n",
    "gt = []\n",
    "prediction_list = []\n",
    "\n",
    "for batch in tqdm(test_dataloader):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = unilogBestModel(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    gt += list(batch[\"labels\"].cpu().numpy())\n",
    "    prediction_list += list(predictions.cpu().numpy())\n",
    "    \n",
    "    metric_acc.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    metric_f1.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    metric_precision.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    metric_recall.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    \n",
    "print(metric_acc.compute())\n",
    "print(metric_f1.compute())\n",
    "print(metric_precision.compute())\n",
    "print(metric_recall.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1867664e-7396-4392-8bcf-4a93bd45b724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.960463\n",
       "1    0.039537\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader.dataset.to_pandas()[\"labels\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e2decb0-f9d0-4867-a547-7ece1216b158",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.960463\n",
       "1    0.039537\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader.dataset.to_pandas()[\"labels\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8add446-f237-49f6-a436-5dc17bba4444",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.960463\n",
       "0    0.039537\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader.dataset.to_pandas()[\"labels\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eba5245f-b95f-47e2-99d9-d624b689e740",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9604633593553261}\n",
      "{'f1': 0.9798330122029544}\n",
      "{'precision': 0.9604633593553261}\n",
      "{'recall': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"{'accuracy': 0.9604633593553261}\n",
    "{'f1': 0.9798330122029544}\n",
    "{'precision': 0.9604633593553261}\n",
    "{'recall': 1.0}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
